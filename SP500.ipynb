{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9fd24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.23.5 pandas==1.5.3 yfinance --no-cache-dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02e2dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2a580ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03 00:00:00-05:00</th>\n",
       "      <td>1469.250000</td>\n",
       "      <td>1478.000000</td>\n",
       "      <td>1438.359985</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>931800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04 00:00:00-05:00</th>\n",
       "      <td>1455.219971</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>1397.430054</td>\n",
       "      <td>1399.420044</td>\n",
       "      <td>1009000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05 00:00:00-05:00</th>\n",
       "      <td>1399.420044</td>\n",
       "      <td>1413.270020</td>\n",
       "      <td>1377.680054</td>\n",
       "      <td>1402.109985</td>\n",
       "      <td>1085500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06 00:00:00-05:00</th>\n",
       "      <td>1402.109985</td>\n",
       "      <td>1411.900024</td>\n",
       "      <td>1392.099976</td>\n",
       "      <td>1403.449951</td>\n",
       "      <td>1092300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07 00:00:00-05:00</th>\n",
       "      <td>1403.449951</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>1400.729980</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>1225200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-23 00:00:00-05:00</th>\n",
       "      <td>6076.319824</td>\n",
       "      <td>6118.729980</td>\n",
       "      <td>6074.669922</td>\n",
       "      <td>6118.709961</td>\n",
       "      <td>4432250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-24 00:00:00-05:00</th>\n",
       "      <td>6121.430176</td>\n",
       "      <td>6128.180176</td>\n",
       "      <td>6088.740234</td>\n",
       "      <td>6101.240234</td>\n",
       "      <td>4214250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-27 00:00:00-05:00</th>\n",
       "      <td>5969.040039</td>\n",
       "      <td>6017.169922</td>\n",
       "      <td>5962.919922</td>\n",
       "      <td>6012.279785</td>\n",
       "      <td>5198750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-28 00:00:00-05:00</th>\n",
       "      <td>6026.970215</td>\n",
       "      <td>6074.540039</td>\n",
       "      <td>5994.629883</td>\n",
       "      <td>6067.700195</td>\n",
       "      <td>4473640000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-29 00:00:00-05:00</th>\n",
       "      <td>6057.700195</td>\n",
       "      <td>6062.830078</td>\n",
       "      <td>6012.959961</td>\n",
       "      <td>6039.310059</td>\n",
       "      <td>4115310000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6307 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Date                                                                            \n",
       "2000-01-03 00:00:00-05:00  1469.250000  1478.000000  1438.359985  1455.219971   \n",
       "2000-01-04 00:00:00-05:00  1455.219971  1455.219971  1397.430054  1399.420044   \n",
       "2000-01-05 00:00:00-05:00  1399.420044  1413.270020  1377.680054  1402.109985   \n",
       "2000-01-06 00:00:00-05:00  1402.109985  1411.900024  1392.099976  1403.449951   \n",
       "2000-01-07 00:00:00-05:00  1403.449951  1441.469971  1400.729980  1441.469971   \n",
       "...                                ...          ...          ...          ...   \n",
       "2025-01-23 00:00:00-05:00  6076.319824  6118.729980  6074.669922  6118.709961   \n",
       "2025-01-24 00:00:00-05:00  6121.430176  6128.180176  6088.740234  6101.240234   \n",
       "2025-01-27 00:00:00-05:00  5969.040039  6017.169922  5962.919922  6012.279785   \n",
       "2025-01-28 00:00:00-05:00  6026.970215  6074.540039  5994.629883  6067.700195   \n",
       "2025-01-29 00:00:00-05:00  6057.700195  6062.830078  6012.959961  6039.310059   \n",
       "\n",
       "                               Volume  Dividends  Stock Splits  \n",
       "Date                                                            \n",
       "2000-01-03 00:00:00-05:00   931800000        0.0           0.0  \n",
       "2000-01-04 00:00:00-05:00  1009000000        0.0           0.0  \n",
       "2000-01-05 00:00:00-05:00  1085500000        0.0           0.0  \n",
       "2000-01-06 00:00:00-05:00  1092300000        0.0           0.0  \n",
       "2000-01-07 00:00:00-05:00  1225200000        0.0           0.0  \n",
       "...                               ...        ...           ...  \n",
       "2025-01-23 00:00:00-05:00  4432250000        0.0           0.0  \n",
       "2025-01-24 00:00:00-05:00  4214250000        0.0           0.0  \n",
       "2025-01-27 00:00:00-05:00  5198750000        0.0           0.0  \n",
       "2025-01-28 00:00:00-05:00  4473640000        0.0           0.0  \n",
       "2025-01-29 00:00:00-05:00  4115310000        0.0           0.0  \n",
       "\n",
       "[6307 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch S&P 500 data from Yahoo Finance\n",
    "sp500 = yf.Ticker(\"^GSPC\")\n",
    "df = sp500.history(start=\"2000-01-01\") \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5fcabf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Tomorrow_close</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03 00:00:00-05:00</th>\n",
       "      <td>1469.250000</td>\n",
       "      <td>1478.000000</td>\n",
       "      <td>1438.359985</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>931800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1399.420044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04 00:00:00-05:00</th>\n",
       "      <td>1455.219971</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>1397.430054</td>\n",
       "      <td>1399.420044</td>\n",
       "      <td>1009000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1402.109985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05 00:00:00-05:00</th>\n",
       "      <td>1399.420044</td>\n",
       "      <td>1413.270020</td>\n",
       "      <td>1377.680054</td>\n",
       "      <td>1402.109985</td>\n",
       "      <td>1085500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1403.449951</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06 00:00:00-05:00</th>\n",
       "      <td>1402.109985</td>\n",
       "      <td>1411.900024</td>\n",
       "      <td>1392.099976</td>\n",
       "      <td>1403.449951</td>\n",
       "      <td>1092300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07 00:00:00-05:00</th>\n",
       "      <td>1403.449951</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>1400.729980</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>1225200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1457.599976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-23 00:00:00-05:00</th>\n",
       "      <td>6076.319824</td>\n",
       "      <td>6118.729980</td>\n",
       "      <td>6074.669922</td>\n",
       "      <td>6118.709961</td>\n",
       "      <td>4432250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6101.240234</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-24 00:00:00-05:00</th>\n",
       "      <td>6121.430176</td>\n",
       "      <td>6128.180176</td>\n",
       "      <td>6088.740234</td>\n",
       "      <td>6101.240234</td>\n",
       "      <td>4214250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6012.279785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-27 00:00:00-05:00</th>\n",
       "      <td>5969.040039</td>\n",
       "      <td>6017.169922</td>\n",
       "      <td>5962.919922</td>\n",
       "      <td>6012.279785</td>\n",
       "      <td>5198750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6067.700195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-28 00:00:00-05:00</th>\n",
       "      <td>6026.970215</td>\n",
       "      <td>6074.540039</td>\n",
       "      <td>5994.629883</td>\n",
       "      <td>6067.700195</td>\n",
       "      <td>4473640000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6039.310059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-29 00:00:00-05:00</th>\n",
       "      <td>6057.700195</td>\n",
       "      <td>6062.830078</td>\n",
       "      <td>6012.959961</td>\n",
       "      <td>6039.310059</td>\n",
       "      <td>4115310000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6307 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Date                                                                            \n",
       "2000-01-03 00:00:00-05:00  1469.250000  1478.000000  1438.359985  1455.219971   \n",
       "2000-01-04 00:00:00-05:00  1455.219971  1455.219971  1397.430054  1399.420044   \n",
       "2000-01-05 00:00:00-05:00  1399.420044  1413.270020  1377.680054  1402.109985   \n",
       "2000-01-06 00:00:00-05:00  1402.109985  1411.900024  1392.099976  1403.449951   \n",
       "2000-01-07 00:00:00-05:00  1403.449951  1441.469971  1400.729980  1441.469971   \n",
       "...                                ...          ...          ...          ...   \n",
       "2025-01-23 00:00:00-05:00  6076.319824  6118.729980  6074.669922  6118.709961   \n",
       "2025-01-24 00:00:00-05:00  6121.430176  6128.180176  6088.740234  6101.240234   \n",
       "2025-01-27 00:00:00-05:00  5969.040039  6017.169922  5962.919922  6012.279785   \n",
       "2025-01-28 00:00:00-05:00  6026.970215  6074.540039  5994.629883  6067.700195   \n",
       "2025-01-29 00:00:00-05:00  6057.700195  6062.830078  6012.959961  6039.310059   \n",
       "\n",
       "                               Volume  Dividends  Stock Splits  \\\n",
       "Date                                                             \n",
       "2000-01-03 00:00:00-05:00   931800000        0.0           0.0   \n",
       "2000-01-04 00:00:00-05:00  1009000000        0.0           0.0   \n",
       "2000-01-05 00:00:00-05:00  1085500000        0.0           0.0   \n",
       "2000-01-06 00:00:00-05:00  1092300000        0.0           0.0   \n",
       "2000-01-07 00:00:00-05:00  1225200000        0.0           0.0   \n",
       "...                               ...        ...           ...   \n",
       "2025-01-23 00:00:00-05:00  4432250000        0.0           0.0   \n",
       "2025-01-24 00:00:00-05:00  4214250000        0.0           0.0   \n",
       "2025-01-27 00:00:00-05:00  5198750000        0.0           0.0   \n",
       "2025-01-28 00:00:00-05:00  4473640000        0.0           0.0   \n",
       "2025-01-29 00:00:00-05:00  4115310000        0.0           0.0   \n",
       "\n",
       "                           Tomorrow_close  Target  \n",
       "Date                                               \n",
       "2000-01-03 00:00:00-05:00     1399.420044       0  \n",
       "2000-01-04 00:00:00-05:00     1402.109985       1  \n",
       "2000-01-05 00:00:00-05:00     1403.449951       1  \n",
       "2000-01-06 00:00:00-05:00     1441.469971       1  \n",
       "2000-01-07 00:00:00-05:00     1457.599976       1  \n",
       "...                                   ...     ...  \n",
       "2025-01-23 00:00:00-05:00     6101.240234       0  \n",
       "2025-01-24 00:00:00-05:00     6012.279785       0  \n",
       "2025-01-27 00:00:00-05:00     6067.700195       1  \n",
       "2025-01-28 00:00:00-05:00     6039.310059       0  \n",
       "2025-01-29 00:00:00-05:00             NaN       0  \n",
       "\n",
       "[6307 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define target variable: 1 if price goes up, 0 if it goes down\n",
    "df[\"Tomorrow_close\"] = df[\"Close\"].shift(-1)\n",
    "df[\"Target\"] = (df[\"Tomorrow_close\"] > df[\"Close\"]).astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2b5ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering - Create Predictors\n",
    "df[\"Return\"] = df[\"Close\"].pct_change()  # Daily return percentage\n",
    "df[\"SMA_5\"] = df[\"Close\"].rolling(5).mean()  # 5-day Simple Moving Average\n",
    "df[\"SMA_20\"] = df[\"Close\"].rolling(20).mean()  # 20-day Simple Moving Average\n",
    "df[\"Volatility\"] = df[\"Return\"].rolling(10).std()  # Rolling standard deviation (Volatility)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7cfb374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values caused by rolling calculations\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24e4eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictors (X) and target (y)\n",
    "predictors = [\"Return\", \"SMA_5\", \"SMA_20\", \"Volatility\", \"Volume\"]\n",
    "X = df[predictors]\n",
    "y = df[\"Target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "534c0d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbcf399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the predictor variables\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit on training data\n",
    "X_test = scaler.transform(X_test)  # Transform test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc004c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, n_estimators=200, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=5, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "711f4764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Model Accuracy: 0.5358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.07      0.13       582\n",
      "           1       0.54      0.93      0.68       676\n",
      "\n",
      "    accuracy                           0.54      1258\n",
      "   macro avg       0.51      0.50      0.40      1258\n",
      "weighted avg       0.52      0.54      0.43      1258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate Model Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"ðŸ“Š Model Accuracy: {accuracy:.4f}\")  # Print accuracy score\n",
    "print(classification_report(y_test, y_pred))  # Print detailed performance report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f523841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Prediction: The S&P 500 is likely to go UP tomorrow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanngo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get the latest day's data for prediction\n",
    "latest_data = X.iloc[-1:].values  # Get the last row (latest data)\n",
    "latest_data = scaler.transform(latest_data)  # Apply scaling\n",
    "\n",
    "# Predict tomorrow's movement\n",
    "tomorrow_prediction = model.predict(latest_data)\n",
    "\n",
    "# Print prediction result\n",
    "if tomorrow_prediction[0] == 1:\n",
    "    print(\"ðŸ“ˆ Prediction: The S&P 500 is likely to go UP tomorrow.\")\n",
    "else:\n",
    "    print(\"ðŸ“‰ Prediction: The S&P 500 is likely to go DOWN tomorrow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0cd7d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Model Accuracy: 0.5437\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.03      0.05       808\n",
      "           1       0.54      0.98      0.70       956\n",
      "\n",
      "    accuracy                           0.54      1764\n",
      "   macro avg       0.54      0.50      0.38      1764\n",
      "weighted avg       0.54      0.54      0.40      1764\n",
      "\n",
      "ðŸ“ˆ Prediction: The S&P 500 is likely to go UP tomorrow.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ðŸ“Œ Step 1: Download S&P 500 Data\n",
    "sp500 = yf.Ticker(\"^GSPC\")\n",
    "df = sp500.history(start=\"1990-01-01\")   # Get 10 years of data\n",
    "\n",
    "# ðŸ“Œ Step 2: Feature Engineering (Predictors)\n",
    "df[\"Tomorrow_Close\"] = df[\"Close\"].shift(-1)  # Next day's closing price\n",
    "df[\"Target\"] = (df[\"Tomorrow_Close\"] > df[\"Close\"]).astype(int)  # 1 if price goes up, 0 if down\n",
    "\n",
    "# Create Technical Indicators\n",
    "df[\"Return\"] = df[\"Close\"].pct_change()  # Daily return\n",
    "df[\"SMA_5\"] = df[\"Close\"].rolling(5).mean()  # 5-day Simple Moving Average\n",
    "df[\"SMA_20\"] = df[\"Close\"].rolling(20).mean()  # 20-day Moving Average\n",
    "df[\"Volatility\"] = df[\"Return\"].rolling(10).std()  # Rolling volatility\n",
    "\n",
    "# Drop rows with NaNs\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# ðŸ“Œ Step 3: Define Features and Target\n",
    "predictors = [\"Return\", \"SMA_5\", \"SMA_20\", \"Volatility\", \"Volume\"]\n",
    "X = df[predictors]\n",
    "y = df[\"Target\"]\n",
    "\n",
    "# ðŸ“Œ Step 4: Train-Test Split (No Shuffling for Time-Series Data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# ðŸ“Œ Step 5: Normalize the Features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ðŸ“Œ Step 6: Train a Random Forest Model\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ðŸ“Œ Step 7: Make Predictions & Evaluate Performance\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"ðŸ“Š Model Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ðŸ“Œ Step 8: Predict Tomorrowâ€™s Market Movement\n",
    "latest_data = X.iloc[-1:].values  # Get today's features\n",
    "latest_data = scaler.transform(latest_data)\n",
    "tomorrow_prediction = model.predict(latest_data)\n",
    "\n",
    "if tomorrow_prediction[0] == 1:\n",
    "    print(\"ðŸ“ˆ Prediction: The S&P 500 is likely to go UP tomorrow.\")\n",
    "else:\n",
    "    print(\"ðŸ“‰ Prediction: The S&P 500 is likely to go DOWN tomorrow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61cbea56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Model Accuracy: 0.5334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.18      0.27       806\n",
      "           1       0.55      0.83      0.66       958\n",
      "\n",
      "    accuracy                           0.53      1764\n",
      "   macro avg       0.51      0.51      0.46      1764\n",
      "weighted avg       0.51      0.53      0.48      1764\n",
      "\n",
      "ðŸ“ˆ The S&P 500 is likely to go UP tomorrow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanngo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fetch S&P 500 data\n",
    "sp500 = yf.Ticker(\"^GSPC\")\n",
    "df = sp500.history(start=\"1990-01-01\")\n",
    "\n",
    "# Define target variable (1 if price goes up, 0 if it goes down)\n",
    "df[\"Tomorrow_Close\"] = df[\"Close\"].shift(-1)\n",
    "df[\"Target\"] = (df[\"Tomorrow_Close\"] > df[\"Close\"]).astype(int)\n",
    "\n",
    "# Feature Engineering\n",
    "df[\"Return\"] = df[\"Close\"].pct_change()\n",
    "df[\"SMA_5\"] = df[\"Close\"].rolling(5).mean()\n",
    "df[\"SMA_20\"] = df[\"Close\"].rolling(20).mean()\n",
    "df[\"Volatility\"] = df[\"Return\"].rolling(10).std()\n",
    "\n",
    "# Add Advanced Indicators\n",
    "df[\"RSI\"] = df[\"Close\"].rolling(14).apply(lambda x: 100 - (100 / (1 + np.mean(x[x > x.mean()]) / np.mean(x[x <= x.mean()]))))\n",
    "df[\"EMA_12\"] = df[\"Close\"].ewm(span=12, adjust=False).mean()\n",
    "df[\"EMA_26\"] = df[\"Close\"].ewm(span=26, adjust=False).mean()\n",
    "df[\"MACD\"] = df[\"EMA_12\"] - df[\"EMA_26\"]\n",
    "df[\"Upper_Band\"] = df[\"SMA_20\"] + (df[\"Close\"].rolling(20).std() * 2)\n",
    "df[\"Lower_Band\"] = df[\"SMA_20\"] - (df[\"Close\"].rolling(20).std() * 2)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Define predictors and target\n",
    "predictors = [\"Return\", \"SMA_5\", \"SMA_20\", \"Volatility\", \"RSI\", \"MACD\", \"Upper_Band\", \"Lower_Band\", \"Volume\"]\n",
    "X = df[predictors]\n",
    "y = df[\"Target\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=500, max_depth=7, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions & evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"ðŸ“Š Model Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Predict tomorrow's movement\n",
    "latest_data = X.iloc[-1:].values\n",
    "latest_data = scaler.transform(latest_data)\n",
    "tomorrow_prediction = model.predict(latest_data)\n",
    "\n",
    "if tomorrow_prediction[0] == 1:\n",
    "    print(\"ðŸ“ˆ The S&P 500 is likely to go UP tomorrow.\")\n",
    "else:\n",
    "    print(\"ðŸ“‰ The S&P 500 is likely to go DOWN tomorrow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ccb08d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/jordanngo/anaconda3/lib/python3.11/site-packages (2.1.3)\r\n",
      "Requirement already satisfied: numpy in /Users/jordanngo/anaconda3/lib/python3.11/site-packages (from xgboost) (1.23.5)\r\n",
      "Requirement already satisfied: scipy in /Users/jordanngo/anaconda3/lib/python3.11/site-packages (from xgboost) (1.11.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "702be1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanngo/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5253 - loss: 0.6924 - val_accuracy: 0.5234 - val_loss: 0.6920\n",
      "Epoch 2/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5259 - loss: 0.6922 - val_accuracy: 0.4612 - val_loss: 0.6969\n",
      "Epoch 3/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5342 - loss: 0.6908 - val_accuracy: 0.5035 - val_loss: 0.6941\n",
      "Epoch 4/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5358 - loss: 0.6911 - val_accuracy: 0.5224 - val_loss: 0.6922\n",
      "Epoch 5/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5405 - loss: 0.6904 - val_accuracy: 0.5239 - val_loss: 0.6927\n",
      "Epoch 6/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5381 - loss: 0.6902 - val_accuracy: 0.4572 - val_loss: 0.7019\n",
      "Epoch 7/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5293 - loss: 0.6911 - val_accuracy: 0.5224 - val_loss: 0.6921\n",
      "Epoch 8/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5421 - loss: 0.6897 - val_accuracy: 0.5159 - val_loss: 0.6939\n",
      "Epoch 9/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5280 - loss: 0.6917 - val_accuracy: 0.4687 - val_loss: 0.7030\n",
      "Epoch 10/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5405 - loss: 0.6899 - val_accuracy: 0.5239 - val_loss: 0.6915\n",
      "Epoch 11/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5329 - loss: 0.6907 - val_accuracy: 0.4841 - val_loss: 0.6971\n",
      "Epoch 12/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5395 - loss: 0.6896 - val_accuracy: 0.5209 - val_loss: 0.6925\n",
      "Epoch 13/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5384 - loss: 0.6902 - val_accuracy: 0.4950 - val_loss: 0.6965\n",
      "Epoch 14/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5393 - loss: 0.6895 - val_accuracy: 0.4871 - val_loss: 0.6986\n",
      "Epoch 15/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5291 - loss: 0.6910 - val_accuracy: 0.5050 - val_loss: 0.6956\n",
      "Epoch 16/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5459 - loss: 0.6890 - val_accuracy: 0.4806 - val_loss: 0.7031\n",
      "Epoch 17/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5305 - loss: 0.6911 - val_accuracy: 0.5154 - val_loss: 0.6957\n",
      "Epoch 18/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5291 - loss: 0.6913 - val_accuracy: 0.5239 - val_loss: 0.6950\n",
      "Epoch 19/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5210 - loss: 0.6938 - val_accuracy: 0.4881 - val_loss: 0.7017\n",
      "Epoch 20/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5422 - loss: 0.6894 - val_accuracy: 0.4687 - val_loss: 0.7040\n",
      "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "ðŸ“Š LSTM Model Accuracy (Time Period: 40y): 0.4687\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "ðŸ“‰ The S&P 500 is likely to go DOWN tomorrow.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Specify the time period \n",
    "time_period = \"30y\" \n",
    "\n",
    "# ðŸ“Œ Step 1: Fetch S&P 500 Data\n",
    "sp500 = yf.Ticker(\"^GSPC\")\n",
    "df = sp500.history(period=time_period, interval=\"1d\")  # Get data with daily granularity\n",
    "\n",
    "# ðŸ“Œ Step 2: Define Target Variable (1 if price goes up, 0 if down)\n",
    "df[\"Tomorrow_Close\"] = df[\"Close\"].shift(-1)\n",
    "df[\"Target\"] = (df[\"Tomorrow_Close\"] > df[\"Close\"]).astype(int)\n",
    "\n",
    "# ðŸ“Œ Step 3: Feature Engineering\n",
    "df[\"Return\"] = df[\"Close\"].pct_change()\n",
    "df[\"SMA_5\"] = df[\"Close\"].rolling(5).mean()\n",
    "df[\"SMA_20\"] = df[\"Close\"].rolling(20).mean()\n",
    "df[\"Volatility\"] = df[\"Return\"].rolling(10).std()\n",
    "\n",
    "# Drop NaN values (caused by rolling calculations)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# ðŸ“Œ Step 4: Define Predictors\n",
    "predictors = [\"Return\", \"SMA_5\", \"SMA_20\", \"Volatility\", \"Volume\"]\n",
    "X = df[predictors]\n",
    "y = df[\"Target\"]\n",
    "\n",
    "# ðŸ“Œ Step 5: Normalize the Data for LSTM\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ðŸ“Œ Step 6: Convert Data into Sequences for LSTM\n",
    "def create_sequences(data, target, seq_length=10):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X_seq.append(data[i:i+seq_length])\n",
    "        y_seq.append(target[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_length = 10  # ðŸ”¹ Change this to 20 or 30 for longer-term patterns\n",
    "X_lstm, y_lstm = create_sequences(X_scaled, y, seq_length)\n",
    "\n",
    "# ðŸ“Œ Step 7: Train-Test Split\n",
    "train_size = int(len(X_lstm) * 0.8)\n",
    "X_train, X_test = X_lstm[:train_size], X_lstm[train_size:]\n",
    "y_train, y_test = y_lstm[:train_size], y_lstm[train_size:]\n",
    "\n",
    "# ðŸ“Œ Step 8: Build LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# ðŸ“Œ Step 9: Compile Model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# ðŸ“Œ Step 10: Train the Model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# ðŸ“Œ Step 11: Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# ðŸ“Œ Step 12: Evaluate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"ðŸ“Š LSTM Model Accuracy (Time Period: {time_period}): {accuracy:.4f}\")\n",
    "\n",
    "# ðŸ“Œ Step 13: Predict Tomorrow's Movement\n",
    "latest_data = X_scaled[-seq_length:].reshape(1, seq_length, X_scaled.shape[1])\n",
    "tomorrow_prediction = model.predict(latest_data)\n",
    "\n",
    "if tomorrow_prediction[0][0] > 0.5:\n",
    "    print(\"ðŸ“ˆ The S&P 500 is likely to go UP tomorrow.\")\n",
    "else:\n",
    "    print(\"ðŸ“‰ The S&P 500 is likely to go DOWN tomorrow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1fcd934a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ace-tools\n",
      "  Obtaining dependency information for ace-tools from https://files.pythonhosted.org/packages/27/c4/402d3ae2ecbfe72fbdcb2769f55580f1c54a3ca110c44e1efc034516a499/ace_tools-0.0-py3-none-any.whl.metadata\n",
      "  Downloading ace_tools-0.0-py3-none-any.whl.metadata (300 bytes)\n",
      "Downloading ace_tools-0.0-py3-none-any.whl (1.1 kB)\n",
      "Installing collected packages: ace-tools\n",
      "Successfully installed ace-tools-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ace-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4eff7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Tomorrow's Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JNJ</td>\n",
       "      <td>0.512472</td>\n",
       "      <td>ðŸ“ˆ UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PG</td>\n",
       "      <td>0.462018</td>\n",
       "      <td>ðŸ“‰ DOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KO</td>\n",
       "      <td>0.528912</td>\n",
       "      <td>ðŸ“ˆ UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.537415</td>\n",
       "      <td>ðŸ“ˆ UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPY</td>\n",
       "      <td>0.483209</td>\n",
       "      <td>ðŸ“‰ DOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VIG</td>\n",
       "      <td>0.517021</td>\n",
       "      <td>ðŸ“ˆ UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XLV</td>\n",
       "      <td>0.517557</td>\n",
       "      <td>ðŸ“ˆ UP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock  Accuracy Tomorrow's Prediction\n",
       "0   JNJ  0.512472                  ðŸ“ˆ UP\n",
       "1    PG  0.462018                ðŸ“‰ DOWN\n",
       "2    KO  0.528912                  ðŸ“ˆ UP\n",
       "3  MSFT  0.537415                  ðŸ“ˆ UP\n",
       "4   SPY  0.483209                ðŸ“‰ DOWN\n",
       "5   VIG  0.517021                  ðŸ“ˆ UP\n",
       "6   XLV  0.517557                  ðŸ“ˆ UP"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress warnings for clean output\n",
    "\n",
    "# ðŸ”¹ Choose multiple stable stocks to analyze\n",
    "ticker_symbols = [\"JNJ\", \"PG\", \"KO\", \"MSFT\", \"SPY\", \"VIG\", \"XLV\"]  # Add more if needed\n",
    "\n",
    "# ðŸ“Œ Store results in a DataFrame\n",
    "results = []\n",
    "\n",
    "# ðŸ“Œ Loop through each stock\n",
    "for ticker_symbol in ticker_symbols:\n",
    "    try:\n",
    "        # ðŸ“Œ Step 1: Download Stock Data\n",
    "        stock = yf.Ticker(ticker_symbol)\n",
    "        df = stock.history(start=\"1990-01-01\", interval=\"1d\")  # Get daily data since 1990\n",
    "        \n",
    "        if df.empty:\n",
    "            print(f\"âš ï¸ No data found for {ticker_symbol}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # ðŸ“Œ Step 2: Feature Engineering (Predictors)\n",
    "        df[\"Tomorrow_Close\"] = df[\"Close\"].shift(-1)  # Next day's closing price\n",
    "        df[\"Target\"] = (df[\"Tomorrow_Close\"] > df[\"Close\"]).astype(int)  # 1 if price goes up, 0 if down\n",
    "\n",
    "        # Create Technical Indicators\n",
    "        df[\"Return\"] = df[\"Close\"].pct_change()  # Daily return\n",
    "        df[\"SMA_5\"] = df[\"Close\"].rolling(5).mean()  # 5-day Simple Moving Average\n",
    "        df[\"SMA_20\"] = df[\"Close\"].rolling(20).mean()  # 20-day Moving Average\n",
    "        df[\"Volatility\"] = df[\"Return\"].rolling(10).std()  # Rolling volatility\n",
    "\n",
    "        # Drop rows with NaNs\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        # ðŸ“Œ Step 3: Define Features and Target\n",
    "        predictors = [\"Return\", \"SMA_5\", \"SMA_20\", \"Volatility\", \"Volume\"]\n",
    "        X = df[predictors]\n",
    "        y = df[\"Target\"]\n",
    "\n",
    "        # ðŸ“Œ Step 4: Train-Test Split (No Shuffling for Time-Series Data)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # ðŸ“Œ Step 5: Normalize the Features\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # ðŸ“Œ Step 6: Train a Random Forest Model\n",
    "        model = RandomForestClassifier(n_estimators=200, max_depth=5, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # ðŸ“Œ Step 7: Make Predictions & Evaluate Performance\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # ðŸ“Œ Step 8: Predict Tomorrowâ€™s Market Movement\n",
    "        latest_data = X.iloc[-1:].values  # Get today's features\n",
    "        latest_data = scaler.transform(latest_data)\n",
    "        tomorrow_prediction = model.predict(latest_data)\n",
    "        movement = \"ðŸ“ˆ UP\" if tomorrow_prediction[0] == 1 else \"ðŸ“‰ DOWN\"\n",
    "\n",
    "        # ðŸ“Œ Store results\n",
    "        results.append({\"Stock\": ticker_symbol, \"Accuracy\": accuracy, \"Tomorrow's Prediction\": movement})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error processing {ticker_symbol}: {e}\")\n",
    "        continue\n",
    "\n",
    "# ðŸ“Š Display Results in a Table\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6cdd8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
